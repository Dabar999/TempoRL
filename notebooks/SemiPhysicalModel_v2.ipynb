{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22c238f",
   "metadata": {},
   "source": [
    "This notebook presents the semi-physical model of the L1 laser in its second version, based on PyTorch.\n",
    "\n",
    "Author: Francesco Capuano, 2022 S17 summer intern @ ELI-beamlines, Prague\n",
    "\n",
    "\n",
    "# Motivation\n",
    "\n",
    "The goal of this project is to maximise second-harmonic efficiency. However, since it is also very much related to the shortest possible pulse shape, we started with developing a strategy to optimise a predefinite set of control parameters so as to minimise the difference between the obtained pulse shape (in the temporal domain) and a target one (which, by default, is the shortest one typically). \n",
    "\n",
    "However, since data are really expensive to empirically collect we resorted to model the underlying dynamics of the whole system, also considering that (even if not exhaustive) there is a significant amount of know-how concerned with the considered dynamics available.\n",
    "This knowledge about the actual physical process is presented in the following Figure. \n",
    "\n",
    "![](images/semi-physical_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af3cc5",
   "metadata": {},
   "source": [
    "The very same diagram can also be represented by means of a **computational graph**, presented in the following Figure: \n",
    "\n",
    "![](images/semiphysicalmodel-computational_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045a362",
   "metadata": {},
   "source": [
    "This visualisation shows how the sequence of operations that do lead to the final temporal shape is the **succession of much more elementary operations**. \n",
    "\n",
    "This is particularly useful when auto-differentiation can be deployed. In this particular setting because, if one represents the semiphysical model as a computational graph, then it is possible to access, very cheaply in terms of computational time and effort (and with high analytical precision), to those **differential information** which are crucial to **apply methods such as Newton Method or any gradient-based method**.\n",
    "\n",
    "Surely enough, such a model is practically applicable only under the assumption that $y_3(\\nu)$ is a *good approximation* of $y_{REAL, 3}(\\nu)$. \n",
    "\n",
    "Luckily enough, various are the frameworks supporting auto-differentiation. One of this is **Pytorch**. Using it basically requires to rewrite the majority of the code present in the initial version of the semi-physical model, considering the data abstraction of this framework, i.e. **tensors** instead of **arrays**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559ed95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and data acquisition\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Tuple\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# these import are necessary to import modules from directories one level back in the folder structure\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.constants import c\n",
    "\n",
    "from utils.LaserModel import LaserModel\n",
    "data_path = \"../data/L1_pump_spectrum.csv\"\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(data_path, header = None)\n",
    "df.columns = [\"Wavelength (nm)\", \"Intensity\"]\n",
    "# converting Wavelength in Frequency\n",
    "df[\"Frequency (THz)\"] = df[\"Wavelength (nm)\"].apply(lambda wavelenght: 1e-12 * (c/(wavelenght * 1e-9)))\n",
    "# clipping everything that is negative\n",
    "df[\"Intensity\"] = df[\"Intensity\"].apply(lambda intensity: np.clip(intensity, a_min = 0, a_max = None))\n",
    "# the observations must be returned for increasing values of frequency\n",
    "df = df.sort_values(by = \"Frequency (THz)\")\n",
    "\n",
    "frequency, intensity = df.loc[:, \"Frequency (THz)\"].values, df.loc[:, \"Intensity\"].values\n",
    "intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min())\n",
    "field = np.sqrt(intensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab8a15b",
   "metadata": {},
   "source": [
    "Once the data are ingested it is possible to elaborate them as usual (i.e., using already defined methods) since no differential information about this step is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64364806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.physics import *\n",
    "# preprocessing\n",
    "cutoff = np.array((289.95, 291.91)) * 1e12\n",
    "# cutting off the signal\n",
    "frequency_clean, field_clean = cutoff_signal(frequency_cutoff = cutoff, frequency = frequency * 1e12,\n",
    "                                             signal = field)\n",
    "# augmenting the signal\n",
    "frequency_clean_aug, field_clean_aug = equidistant_points(frequency = frequency_clean,\n",
    "                                                          signal = field_clean,\n",
    "                                                          num_points = int(5e4)) # n_points defaults to 5e3\n",
    "# retrieving central carrier\n",
    "central_carrier = central_frequency(frequency = frequency_clean_aug, signal = field_clean_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42e22725",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency, field = torch.from_numpy(frequency), torch.from_numpy(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e52fce",
   "metadata": {},
   "source": [
    "The following functions take care of modelling the first block of the computational graph, the one that takes as input the control quantities (whose gradient must be used) and outputs the physical entity that is necessary to use, i.e. $\\varphi_S$. \n",
    "\n",
    "\n",
    "![](images/computationalgraph_block1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecb42ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_control(central_frequency:float, control:torch.tensor, verse:str = \"to_gdd\")->torch.tensor: \n",
    "        \"\"\"This function translates the control quantities either from Dispersion coefficients (the di's) to GDD, TOD and FOD using a system of linear equations \n",
    "        defined for this very scope or the other way around, according to the string \"verse\".  \n",
    "\n",
    "        Args:\n",
    "            central_frequency (float): Central frequency of the spectrum, expressed in Hz.\n",
    "            control (torch.tensor): Control quanitities (either the di's or delay information). Must be given in SI units.\n",
    "            verse (str, optional): \"to_gdd\" to translate control from dispersion coefficients to (GDD, TOD and FOD), solving Ax = b.\n",
    "            \"to_disp\" to translate (GDD, TOD and FOD) to dispersion coefficient left-multiplying the control by A. Defaults to \"to_gdd\". \n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: The control translated according to the verse considered.\n",
    "        \"\"\"\n",
    "         # central wavelength (using c/f = lambda)\n",
    "        central_wavelength = c / central_frequency\n",
    "\n",
    "        a11 = (-2 * torch.pi * c)/(central_wavelength ** 2) #; a12 = a13 = 0\n",
    "        a21 = (4 * torch.pi * c)/(central_wavelength ** 3); a22 = ((2 * torch.pi * c)/(central_wavelength ** 2))**2 # a23 = 0\n",
    "        a31 = (-12 * torch.pi * c)/(central_wavelength ** 4); a32 = -(24 * (torch.pi * c) ** 2)/(central_wavelength ** 5); a33 = -((2 * torch.pi * c) / (central_wavelength ** 2)) ** 3\n",
    "\n",
    "        A = torch.tensor([\n",
    "            [a11, 0, 0], \n",
    "            [a21, a22, 0], \n",
    "            [a31, a32, a33]\n",
    "        ], dtype = torch.float64\n",
    "        )\n",
    "\n",
    "        if verse.lower() == \"to_gdd\": \n",
    "            d2, d3, d4 = control\n",
    "            # solving the conversion system using forward substitution\n",
    "            GDD = d2 / a11; TOD = (d3 - a21 * GDD)/(a22); FOD = (d4 - a31 * GDD - a32 * TOD)/(a33)\n",
    "            # grouping the tensors maintaing information on the gradient\n",
    "            return torch.stack([GDD, TOD, FOD])\n",
    "\n",
    "        elif verse.lower() == \"to_disp\": \n",
    "            return A @ control\n",
    "        else: \n",
    "            raise ValueError('Control translatin is either \"to_gdd\" or \"to_disp\"!')\n",
    "\n",
    "def phase_equation(frequency:torch.tensor, central_frequency:float, control:torch.tensor) -> torch.tensor: \n",
    "    \"\"\"This function returns the phase with respect to the frequency and some control parameters.\n",
    "\n",
    "    Args:\n",
    "        frequency (torch.tensor): Tensor of frequencies considered (measured in Hz)\n",
    "        central_frequency (float): Central frequency, not angular (measured in Hz).\n",
    "        control (torch.tensor): Control parameters to be used to create the phase. It contains GDD, TOD and FOD in s^2, s^3 and s^4.\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: The phase with respect to the frequency, measured in radiants.\n",
    "    \"\"\"\n",
    "    GDD, TOD, FOD = control\n",
    "    phase = \\\n",
    "            (1/2)* GDD * (2*torch.pi * (frequency - central_frequency))**2 + \\\n",
    "            (1/6)* TOD * (2*torch.pi * (frequency - central_frequency))**3 + \\\n",
    "            (1/24)* FOD * (2*torch.pi * (frequency - central_frequency))**4\n",
    "    return phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968de7b4",
   "metadata": {},
   "source": [
    "Considering now the complete fictional control vector $\\psi = (d_2, d_3, d_4)$ these functions can be tested on whether or not they can store gradient informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e0fc8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control translator gradient:  <StackBackward0 object at 0x7fd523fd8880>\n",
      "Phase function gradient:  <AddBackward0 object at 0x7fd523fd8880>\n"
     ]
    }
   ],
   "source": [
    "psi = torch.rand(size = (3,), requires_grad = True, dtype = torch.double)\n",
    "translated_control = translate_control(central_frequency = central_carrier, control = psi, verse = \"to_gdd\")\n",
    "print(\"Control translator gradient: \", translated_control.grad_fn)\n",
    "\n",
    "obtained_phase = phase_equation(frequency = frequency,\n",
    "                                central_frequency = central_carrier,\n",
    "                                control = translated_control)\n",
    "print(\"Phase function gradient: \", obtained_phase.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120ecfe",
   "metadata": {},
   "source": [
    "Once is it clear that this first block does propagate differential information it is important to model the second block of the computational graph, which is implementing a key operation for the whole process. \n",
    "\n",
    "\n",
    "![](images/computationalgraph_block2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3143bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impose_phase(spectrum:torch.tensor, phase:torch.tensor)->torch.tensor: \n",
    "    \"\"\"This function imposes a phase on a particular signal.\n",
    "    \n",
    "    Args: \n",
    "        spectrum (torch.tensor): Tensor representing the signal considered.\n",
    "        phase (torch.tensor): The phase to impose on the signal.\n",
    "    \n",
    "    Returns: \n",
    "        torch.tensor: New spectrum with modified phase\n",
    "    \"\"\"\n",
    "    return spectrum * torch.exp(1j * phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3092dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x7fd525482350>\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y1 = impose_phase(field, obtained_phase)\n",
    "print(\"Phase imposition gradient: \"y1.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cccc3",
   "metadata": {},
   "source": [
    "This very block will be used many other times in the whole computation of the final shape, hence its usefulness. \n",
    "\n",
    "Furthermore, it is possible to reproduce the block which models the YB:Yab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92b8d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yb_gain(signal:torch.tensor, intensity_yb:torch.tensor, n_passes:int=50)->torch.tensor: \n",
    "    \"\"\"This function models the passage of the signal in the cristal in which yb:yab gain is observed.\n",
    "    \n",
    "    Args: \n",
    "        signal (torch.tensor): The intensity signal that enters the system considered.\n",
    "        intensity_yb (torch.tensor): The gain intensity of the crystal\n",
    "        n_passes (int, optional): The number of times the beam passes through the crystal where spectrum narrowing is observed. \n",
    "        \n",
    "    Returns: \n",
    "        torch.tensor: New spectrum, narrower because of the gain. \n",
    "    \"\"\"\n",
    "    return signal * (intensity_yb ** n_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1b7fd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x7fd524059a20>\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y1_tilde = yb_gain(y1, torch.rand(size = y1.shape))\n",
    "print(\"Spectrum narrowing function gradient: \", y1_tilde.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94182767",
   "metadata": {},
   "source": [
    "The final black whose modelling is necessary is the block that converts a signal with a given phase to its temporal profile information. This block is represented in the following Figure. \n",
    "\n",
    "\n",
    "![](images/computationalgraph_block3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "179c864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_profile(frequency:torch.tensor, field:torch.tensor, npoints_pad:int=int(1e4), return_time:bool=True) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"This function returns the temporal profile of a given signal represented in the frequency domain. Padding is added so as to have more points and increase FFT algorithm output's quality. \n",
    "\n",
    "    Args:\n",
    "        frequency (torch.tensor): Array of frequencies considered (measured in Hz)\n",
    "        field (torch.tensor): Array of field measured in the frequency domain. \n",
    "        npoints_pad (int, optional): Number of points to be used in padding. Padding will be applied using half of this value on the\n",
    "        right and half on the left. Defaults to int(1e4).\n",
    "        return_time (bool, optional): Whether or not to return also the time frame of the signal to be used on the x-axis. Defaults to True. \n",
    "    Returns:\n",
    "        Tuple[np.array, np.array]: Returns either (time, intensity) (with time measured in in seconds) or intensity only.\n",
    "    \"\"\"\n",
    "    step = torch.diff(frequency)[0]\n",
    "    # centering the array in its peak\n",
    "    time = torch.fft.fftshift(torch.fft.fftfreq(len(frequency) + npoints_pad, d=abs(step)))\n",
    "    # centering the signal in its peak\n",
    "    intensity_frequency = field * torch.conj(field) # only for casting reasons\n",
    "    # going from frequency to time\n",
    "    intensity_time = torch.real(torch.fft.ifft(intensity_frequency))\n",
    "    # normalizing the resulting signal\n",
    "    intensity_time / intensity_time.max() # normalizing\n",
    "    \n",
    "    # either returning time or not according to return_time\n",
    "    if not return_time: \n",
    "        return intensity_time\n",
    "    else: \n",
    "        return time, intensity_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9c61bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal profile function gradient:  <SelectBackward0 object at 0x7fd524058910>\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "time, intensity = temporal_profile(frequency, y1_tilde)\n",
    "print(\"Temporal profile function gradient: \", intensity.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf67a93",
   "metadata": {},
   "source": [
    "Once all of the different blocks have been defined it is possible to group them in one single object representative of the whole process. This object is also presented in `utils/LaserModel_torch.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Computational_Laser: \n",
    "    def __init__(self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
