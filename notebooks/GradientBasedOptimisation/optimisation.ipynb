{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37896c37",
   "metadata": {},
   "source": [
    "This notebook presents an application semi-physical model of the L1 laser in its second version, based on PyTorch.\n",
    "In particular, in this notebook the optimization process of the control parameters is solved using such a model. \n",
    "\n",
    "Author: Francesco Capuano, 2022 S17 summer intern @ ELI-beamlines, Prague\n",
    "\n",
    "\n",
    "# Motivation\n",
    "\n",
    "The goal of this project is to maximise second-harmonic efficiency. However, since this metric is also very much related to the shortest possible pulse shape, we started with developing a strategy to optimise a predefinite set of control parameters so as to minimise the difference between the obtained pulse shape (in the temporal domain) and a target one (which, by default, is the shortest one typically). \n",
    "\n",
    "However, since data are really expensive to empirically collect we resorted to model the underlying dynamics of the whole system, also considering that (even if not exhaustive) there is a significant amount of know-how concerned with the considered dynamics available.\n",
    "\n",
    "After this model is obtained, it is possible to use it to obtain the desired control parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19cdb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ext_Capuano\\Anaconda3\\envs\\elienv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# these import are necessary to import modules from directories one level back in the folder structure\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from utils.se import get_project_root\n",
    "from algorithms.L1_BayesianOptimisation import extract_data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import Bounds\n",
    "import numpy as np\n",
    "\n",
    "frequency, field = extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a9508",
   "metadata": {},
   "source": [
    "The preprocessing steps do not depend on the control parameters, therefore they can take place even in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4001629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "from utils.physics import *\n",
    "# preprocessing\n",
    "cutoff = np.array((289.95, 291.91)) * 1e12\n",
    "# cutting off the signal\n",
    "frequency_clean, field_clean = cutoff_signal(frequency_cutoff = cutoff, frequency = frequency * 1e12,\n",
    "                                             signal = field)\n",
    "# augmenting the signal\n",
    "frequency_clean_aug, field_clean_aug = equidistant_points(frequency = frequency_clean,\n",
    "                                                          signal = field_clean,\n",
    "                                                          num_points = int(3e3)) # n_points defaults to 5e3\n",
    "# retrieving central carrier\n",
    "central_carrier = central_frequency(frequency = frequency_clean_aug, signal = field_clean_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1fc9c",
   "metadata": {},
   "source": [
    "However, to be used in the Computational Laser model, their tensir version is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0860ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.LaserModel_torch import ComputationalLaser as CL\n",
    "\n",
    "intensity = torch.from_numpy(field ** 2)\n",
    "frequency, field = torch.from_numpy(frequency_clean_aug), torch.from_numpy(field_clean_aug)\n",
    "compressor_params = -1 * torch.tensor([267.422 * 1e-24, -2.384 * 1e-36, 9.54893 * 1e-50], dtype = torch.double)\n",
    "\n",
    "laser = CL(frequency = frequency * 1e-12, field = field, compressor_params = compressor_params)\n",
    "target_time, target_profile = laser.transform_limited()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf05df8",
   "metadata": {},
   "source": [
    "Pytorch offers various optimizers which are normally considered to be very well suited in NN. However, with a slight tweak and flexibility of reasoning, they can be applied to this very problem as well, as long as this very problem is actually formulated as one of those Pytorch optimizers aer meant to solve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20753ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserOptimization(torch.nn.Module): \n",
    "    \"\"\"Custom Pytorch model for gradient based optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bounds_control = Bounds(\n",
    "                    # GDD         # TOD          # FOD\n",
    "            lb = (2.3522e-22, -1.003635e-34, 4.774465e-50),\n",
    "            ub = (2.99624e-22, 9.55955e-35, 1.4323395e-49)\n",
    "        )\n",
    "\n",
    "        bounds_matrix = np.vstack((bounds_control.lb, bounds_control.ub)).T\n",
    "        # initialize weights with random numbers\n",
    "        control = torch.distributions.Uniform(\n",
    "            low = torch.from_numpy(bounds_matrix[:, 0]), \n",
    "            high = torch.from_numpy(bounds_matrix[:, 1])\n",
    "        ).sample()\n",
    "\n",
    "        # make weights torch parameters\n",
    "        self.control = torch.nn.Parameter(control).cuda()    \n",
    "        \n",
    "    def objective_function(self, control:torch.tensor) -> float:\n",
    "        \"\"\"\n",
    "        Implements the function to be minimised. In this case such a function will be the L1 norm corrected \n",
    "        with a log barrier to maintain the parameters into the feasible region.\n",
    "        \n",
    "        Args: \n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "    def training_loop(model, optimizer, n=1000):\n",
    "        \"Training loop for torch model.\"\n",
    "        losses = []\n",
    "        for i in range(n):\n",
    "            preds = model(x)\n",
    "            loss = F.mse_loss(preds, y).sqrt()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss)  \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66c409e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lo \u001b[38;5;241m=\u001b[39m \u001b[43mLaserOptimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mLaserOptimization.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m control \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mUniform(\n\u001b[0;32m     16\u001b[0m     low \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(bounds_matrix[:, \u001b[38;5;241m0\u001b[39m]), \n\u001b[0;32m     17\u001b[0m     high \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(bounds_matrix[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m )\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# make weights torch parameters\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ext_Capuano\\Anaconda3\\envs\\elienv\\lib\\site-packages\\torch\\cuda\\__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "lo = LaserOptimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
