{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37896c37",
   "metadata": {},
   "source": [
    "This notebook presents an application semi-physical model of the L1 laser in its second version, based on PyTorch.\n",
    "In particular, in this notebook the optimization process of the control parameters is solved using such a model. \n",
    "\n",
    "Author: Francesco Capuano, 2022 S17 summer intern @ ELI-beamlines, Prague\n",
    "\n",
    "\n",
    "# Motivation\n",
    "\n",
    "The goal of this project is to maximise second-harmonic efficiency. However, since this metric is also very much related to the shortest possible pulse shape, we started with developing a strategy to optimise a predefinite set of control parameters so as to minimise the difference between the obtained pulse shape (in the temporal domain) and a target one (which, by default, is the shortest one typically). \n",
    "\n",
    "However, since data are really expensive to empirically collect we resorted to model the underlying dynamics of the whole system, also considering that (even if not exhaustive) there is a significant amount of know-how concerned with the considered dynamics available.\n",
    "\n",
    "After this model is obtained, it is possible to use it to obtain the desired control parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19cdb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# these import are necessary to import modules from directories one level back in the folder structure\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from utils.se import get_project_root\n",
    "from algorithms.L1_BayesianOptimisation import extract_data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import Bounds\n",
    "import numpy as np\n",
    "\n",
    "frequency, field = extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a9508",
   "metadata": {},
   "source": [
    "The preprocessing steps do not depend on the control parameters, therefore they can take place even in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4001629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "from utils.physics import *\n",
    "# preprocessing\n",
    "cutoff = np.array((289.95, 291.91)) * 1e12\n",
    "# cutting off the signal\n",
    "frequency_clean, field_clean = cutoff_signal(frequency_cutoff = cutoff, frequency = frequency * 1e12,\n",
    "                                             signal = field)\n",
    "# augmenting the signal\n",
    "frequency_clean_aug, field_clean_aug = equidistant_points(frequency = frequency_clean,\n",
    "                                                          signal = field_clean,\n",
    "                                                          num_points = int(3e3)) # n_points defaults to 5e3\n",
    "# retrieving central carrier\n",
    "central_carrier = central_frequency(frequency = frequency_clean_aug, signal = field_clean_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1fc9c",
   "metadata": {},
   "source": [
    "However, to be used in the Computational Laser model, their tensir version is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0860ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.LaserModel_torch import ComputationalLaser as CL\n",
    "\n",
    "intensity = torch.from_numpy(field ** 2)\n",
    "frequency, field = torch.from_numpy(frequency_clean_aug), torch.from_numpy(field_clean_aug)\n",
    "compressor_params = -1 * torch.tensor([267.422 * 1e-24, -2.384 * 1e-36, 9.54893 * 1e-50], dtype = torch.double)\n",
    "\n",
    "laser = CL(frequency = frequency * 1e-12, field = field, compressor_params = compressor_params)\n",
    "target_time, target_profile = laser.transform_limited()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf05df8",
   "metadata": {},
   "source": [
    "Pytorch offers various optimizers which are normally considered to be very well suited in NN. However, with a slight tweak and flexibility of reasoning, they can be applied to this very problem as well, as long as this very problem is actually formulated as one of those Pytorch optimizers aer meant to solve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20753ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserOptimization(torch.nn.Module): \n",
    "    \"\"\"Custom Pytorch model for gradient based optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        bounds_control = Bounds(\n",
    "                    # GDD         # TOD          # FOD\n",
    "            lb = (2.3522e-22, -1.003635e-34, 4.774465e-50),\n",
    "            ub = (2.99624e-22, 9.55955e-35, 1.4323395e-49)\n",
    "        )\n",
    "\n",
    "        bounds_matrix = np.vstack((bounds_control.lb, bounds_control.ub)).T\n",
    "        # initialize weights with random numbers\n",
    "        control = torch.distributions.Uniform(\n",
    "            low = torch.from_numpy(bounds_matrix[:, 0]), \n",
    "            high = torch.from_numpy(bounds_matrix[:, 1])\n",
    "        ).sample()\n",
    "\n",
    "        # make weights torch parameters\n",
    "        self.control = torch.nn.Parameter(control).cuda() if torch.cuda.is_available() else torch.nn.Parameter(control)    \n",
    "        \n",
    "    def objective_function(self, control:torch.tensor) -> float:\n",
    "        \"\"\"\n",
    "        Implements the function to be minimised. In this case such a function will be the L1 norm corrected \n",
    "        with a log barrier to maintain the parameters into the feasible region.\n",
    "        \n",
    "        Args: \n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "    def training_loop(model, optimizer, n=1000):\n",
    "        \"Training loop for torch model.\"\n",
    "        losses = []\n",
    "        for i in range(n):\n",
    "            preds = model(x)\n",
    "            loss = F.mse_loss(preds, y).sqrt()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss)  \n",
    "        return losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
